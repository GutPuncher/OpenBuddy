# Model Downloads

### ModelScope 中文社区

欢迎访问我们的 ModelScope 中文社区，体验热门模型的国内高速下载和一键部署！

https://modelscope.cn/organization/OpenBuddy

### Selected Models (HuggingFace format)

OpenBuddy-Zephyr-7B: https://huggingface.co/OpenBuddy/openbuddy-zephyr-7b-v14.1

- This model exhibits a powerful comprehension capability, and its performance approaches that of our 34B model in certain tasks.

OpenBuddy-StableLM-3B: https://huggingface.co/OpenBuddy/openbuddy-stablelm-3b-v13

- This is the most compact model that still maintains satisfactory language understanding, although its knowledge is somewhat limited

OpenBuddy-Llama2-70B: https://huggingface.co/OpenBuddy/openbuddy-llama2-70b-v10.1-bf16

- Currently, this is our best model for general-purpose applications.

OpenBuddy-Llemma-34B: https://huggingface.co/OpenBuddy/openbuddy-llemma-34b-v13.2

- This model excels in logical reasoning, understanding, and coding capabilities.


### GGUF/GPT-Q/AWQ quantized models

GGUF is a model format utilized by [llama.cpp](https://github.com/ggerganov/llama.cpp), a C++ inference engine tailored for personal-level CPU/GPU implementation.

TheBloke offers GGUF/GPT-Q/AWQ quantized versions of the OpenBuddy models, available here: [link](https://huggingface.co/TheBloke?search_models=openbuddy)

Please note, the quality of the GPT-Q and AWQ quantized models depends on the text data used during quantization. We recommend quantizing the models with your own data when quality is critical in your application.

### More Models

More models are available on our HuggingFace: https://huggingface.co/OpenBuddy


